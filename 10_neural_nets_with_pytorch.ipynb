{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 10 – Building Neural Networks with PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-mlp/blob/main/10_neural_nets_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-mlp/blob/main/10_neural_nets_with_pytorch.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.10 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also requires Scikit-Learn ≥ 1.6.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "import sklearn\n",
    "\n",
    "assert Version(sklearn.__version__) >= Version(\"1.6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we using Colab or Kaggle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Colab, a couple libraries are not pre-installed so we must install them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "if IS_COLAB:\n",
    "    %pip install -q optuna torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we need PyTorch, specifically PyTorch ≥ 2.6.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert Version(torch.__version__) >= Version(\"2.6.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in earlier chapters, let's define the default font sizes to make the figures prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals\n",
    "## PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 50., 80.],\n",
       "        [30., 40., 70.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * (X + 1.0)  # item-wise addition and multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2.7183,   54.5981, 1096.6332],\n",
       "        [   7.3891,   20.0855,  403.4288]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8333)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2., 4., 7.]),\n",
       "indices=tensor([1, 0, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66., 56.],\n",
       "        [56., 49.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 7.],\n",
       "       [2., 3., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 88.,  7.],\n",
       "        [ 2.,  3.,  6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code: demonstrate torch.from_numpy()\n",
    "X2_np = np.array([[1., 4., 7.], [2., 3., 6]])\n",
    "X2 = torch.from_numpy(X2_np)  # X2_np and X2 share the same data in memory\n",
    "X2_np[0, 1] = 88\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1., -99.,   7.],\n",
       "        [  2., -99.,   6.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1] = -99\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 7.],\n",
       "        [2., 0., 6.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.relu_()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensors really resemble NumPy arrays. In fact, they have over 200 common functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'__getattr__, abs, absolute, acos, acosh, add, all, allclose, amax, amin, angle, any, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctan2, arctanh, argmax, argmin, argsort, argwhere, asarray, asin, asinh, atan, atan2, atanh, atleast_1d, atleast_2d, atleast_3d, bincount, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, broadcast_shapes, broadcast_to, can_cast, ceil, clip, column_stack, concat, concatenate, conj, copysign, corrcoef, cos, cosh, count_nonzero, cov, cross, cumprod, cumsum, deg2rad, diag, diagflat, diagonal, diff, divide, dot, dsplit, dstack, dtype, einsum, empty, empty_like, equal, exp, exp2, expm1, eye, finfo, fix, flip, fliplr, flipud, float_power, floor, floor_divide, fmax, fmin, fmod, frexp, from_dlpack, frombuffer, full, full_like, gcd, gradient, greater, greater_equal, heaviside, histogram, histogramdd, hsplit, hstack, hypot, i0, iinfo, imag, inner, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, kron, lcm, ldexp, less, less_equal, linspace, load, log, log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logspace, matmul, max, maximum, mean, median, meshgrid, min, minimum, moveaxis, multiply, nan_to_num, nanmean, nanmedian, nanquantile, nansum, negative, nextafter, nonzero, not_equal, ones, ones_like, outer, positive, pow, prod, promote_types, put, quantile, rad2deg, ravel, real, reciprocal, remainder, reshape, result_type, roll, rot90, round, row_stack, save, searchsorted, select, set_printoptions, sign, signbit, sin, sinc, sinh, sort, split, sqrt, square, squeeze, stack, std, subtract, sum, swapaxes, take, tan, tanh, tensordot, tile, trace, transpose, trapezoid, trapz, tril, tril_indices, triu, triu_indices, true_divide, trunc, typename, unique, unravel_index, vander, var, vdot, vsplit, vstack, where, zeros, zeros_like'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code: list functions that appear both in NumPy and PyTorch\n",
    "functions = lambda mod: set(f for f in dir(mod) if callable(getattr(mod, f)))\n",
    "\", \".join(sorted(functions(torch) & functions(np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "M = M.to(device)\n",
    "M.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 32.],\n",
       "        [32., 77.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = M @ M.T  # run some operations on the GPU\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.1 ms ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "549 µs ± 3.99 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "M = torch.rand((1000, 1000))  # on the CPU\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T\n",
    "\n",
    "M = M.to(device)\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a simple function, $f(x) = x^2$.\n",
    "Calculus tells us that the derivative of this function is $f'(x)=2x$. Let's evaluate $f(5)$ and the derivative $f'(5)$ using autograd. We expect to find $f(5)=5^2=25$ and $f'(5)=2*5=10$. Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "f = x ** 2\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "with torch.no_grad():\n",
    "    x -= learning_rate * x.grad  # gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have used this code for the gradient descent step (but using `no_grad()` is more common for this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_detached = x.detach()\n",
    "x_detached -= learning_rate * x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everything together to get our training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "for iteration in range(100):\n",
    "    f = x ** 2  # forward pass\n",
    "    f.backward()  # backward pass\n",
    "    with torch.no_grad():\n",
    "        x -= learning_rate * x.grad  # gradient descent step\n",
    "    x.grad.zero_()  # reset the gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `x` gets pushed towards 0, since that's the value that minimizes $f(x) = x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0185e-09, requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression\n",
    "## Linear Regression Using Tensors & Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "means = X_train.mean(dim=0, keepdims=True)\n",
    "stds = X_train.std(dim=0, keepdims=True)\n",
    "X_train = (X_train - means) / stds\n",
    "X_valid = (X_valid - means) / stds\n",
    "X_test = (X_test - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch expects the targets to have one row per sample, so let's reshape the targets to be column vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_valid = torch.FloatTensor(y_valid).view(-1, 1)\n",
    "y_test = torch.FloatTensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_features = X_train.shape[1]  # there are 8 input features\n",
    "w = torch.randn((n_features, 1), requires_grad=True)\n",
    "b = torch.tensor(0., requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in the next section, we will build an almost identical model using PyTorch's high-level API. Its results will be slightly different because it will use a different parameter initialization method: it will use a uniform random distribution from $-\\frac{1}{2\\sqrt 2}$ to $+\\frac{1}{2\\sqrt 2}$ to initialize both the weights and the bias term. If you want to get exactly the same result here as in the next section, you can uncomment and run the initialization code in the following cell, instead of the code in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# n_features = X_train.shape[1]  # there are 8 input features\n",
    "# r = 2 ** -1.5  # this is equal to 1 / 2√2\n",
    "# w = torch.empty(n_features, 1).uniform_(-r, r)\n",
    "# b = torch.empty(1).uniform_(-r, r)\n",
    "# w.requires_grad_(True)\n",
    "# b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 16.158456802368164\n",
      "Epoch 2/20, Loss: 4.8793745040893555\n",
      "Epoch 3/20, Loss: 2.255225419998169\n",
      "Epoch 4/20, Loss: 1.3307634592056274\n",
      "Epoch 5/20, Loss: 0.9680691957473755\n",
      "Epoch 6/20, Loss: 0.8142675757408142\n",
      "Epoch 7/20, Loss: 0.7417045831680298\n",
      "Epoch 8/20, Loss: 0.7020701169967651\n",
      "Epoch 9/20, Loss: 0.6765918731689453\n",
      "Epoch 10/20, Loss: 0.6577965021133423\n",
      "Epoch 11/20, Loss: 0.6426151990890503\n",
      "Epoch 12/20, Loss: 0.6297222971916199\n",
      "Epoch 13/20, Loss: 0.6184942126274109\n",
      "Epoch 14/20, Loss: 0.6085968613624573\n",
      "Epoch 15/20, Loss: 0.5998216867446899\n",
      "Epoch 16/20, Loss: 0.592018723487854\n",
      "Epoch 17/20, Loss: 0.5850691795349121\n",
      "Epoch 18/20, Loss: 0.578873336315155\n",
      "Epoch 19/20, Loss: 0.573345422744751\n",
      "Epoch 20/20, Loss: 0.5684100389480591\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = X_train @ w + b\n",
    "    loss = ((y_pred - y_train) ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        b -= learning_rate * b.grad\n",
    "        w -= learning_rate * w.grad\n",
    "        b.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = X_new @ w + b  # use the trained parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8916],\n",
       "        [1.6480],\n",
       "        [2.6577]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using PyTorch's High-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)  # to get reproducible results\n",
    "model = nn.Linear(in_features=n_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3117], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4718],\n",
       "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.3378496170043945\n",
      "Epoch 2/20, Loss: 0.7802939414978027\n",
      "Epoch 3/20, Loss: 0.6253842115402222\n",
      "Epoch 4/20, Loss: 0.6060433983802795\n",
      "Epoch 5/20, Loss: 0.5956299304962158\n",
      "Epoch 6/20, Loss: 0.587356686592102\n",
      "Epoch 7/20, Loss: 0.5802990794181824\n",
      "Epoch 8/20, Loss: 0.5741382837295532\n",
      "Epoch 9/20, Loss: 0.5687101483345032\n",
      "Epoch 10/20, Loss: 0.5639079809188843\n",
      "Epoch 11/20, Loss: 0.5596511363983154\n",
      "Epoch 12/20, Loss: 0.5558737516403198\n",
      "Epoch 13/20, Loss: 0.5525194406509399\n",
      "Epoch 14/20, Loss: 0.5495392084121704\n",
      "Epoch 15/20, Loss: 0.5468900203704834\n",
      "Epoch 16/20, Loss: 0.544533908367157\n",
      "Epoch 17/20, Loss: 0.5424376726150513\n",
      "Epoch 18/20, Loss: 0.5405716300010681\n",
      "Epoch 19/20, Loss: 0.5389097332954407\n",
      "Epoch 20/20, Loss: 0.5374288558959961\n"
     ]
    }
   ],
   "source": [
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8061],\n",
       "        [1.7116],\n",
       "        [2.6973]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_new)  # use the trained model to make predictions\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 5.045480251312256\n",
      "Epoch 2/20, Loss: 2.0523123741149902\n",
      "Epoch 3/20, Loss: 1.0039883852005005\n",
      "Epoch 4/20, Loss: 0.8570139408111572\n",
      "Epoch 5/20, Loss: 0.7740675210952759\n",
      "Epoch 6/20, Loss: 0.7225847244262695\n",
      "Epoch 7/20, Loss: 0.6893726587295532\n",
      "Epoch 8/20, Loss: 0.6669032573699951\n",
      "Epoch 9/20, Loss: 0.6507738828659058\n",
      "Epoch 10/20, Loss: 0.6383934020996094\n",
      "Epoch 11/20, Loss: 0.6281993389129639\n",
      "Epoch 12/20, Loss: 0.6193399429321289\n",
      "Epoch 13/20, Loss: 0.6113173365592957\n",
      "Epoch 14/20, Loss: 0.6038705706596375\n",
      "Epoch 15/20, Loss: 0.5968307852745056\n",
      "Epoch 16/20, Loss: 0.5901119112968445\n",
      "Epoch 17/20, Loss: 0.5836468935012817\n",
      "Epoch 18/20, Loss: 0.5774063467979431\n",
      "Epoch 19/20, Loss: 0.5713554620742798\n",
      "Epoch 20/20, Loss: 0.565444827079773\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()\n",
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Mini-Batch Gradient Descent using DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – build the model just like earlier\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# extra code – build the optimizer and loss function, as earlier\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5900\n",
      "Epoch 2/20, Loss: 0.4046\n",
      "Epoch 3/20, Loss: 0.3801\n",
      "Epoch 4/20, Loss: 0.3629\n",
      "Epoch 5/20, Loss: 0.3529\n",
      "Epoch 6/20, Loss: 0.3520\n",
      "Epoch 7/20, Loss: 0.3408\n",
      "Epoch 8/20, Loss: 0.3427\n",
      "Epoch 9/20, Loss: 0.3406\n",
      "Epoch 10/20, Loss: 0.3378\n",
      "Epoch 11/20, Loss: 0.3304\n",
      "Epoch 12/20, Loss: 0.3267\n",
      "Epoch 13/20, Loss: 0.3244\n",
      "Epoch 14/20, Loss: 0.3221\n",
      "Epoch 15/20, Loss: 0.3186\n",
      "Epoch 16/20, Loss: 0.3149\n",
      "Epoch 17/20, Loss: 0.3123\n",
      "Epoch 18/20, Loss: 0.3111\n",
      "Epoch 19/20, Loss: 0.3088\n",
      "Epoch 20/20, Loss: 0.3072\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, mse, train_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric = metric_fn(y_pred, y_batch)\n",
    "            metrics.append(metric)\n",
    "    return aggregate_fn(torch.stack(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4080, device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "valid_mse = evaluate(model, valid_loader, mse)\n",
    "valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5668, device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
    "\n",
    "evaluate(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mse.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, mse,\n",
    "         aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_tm(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
    "    return metric.compute()  # compute the final result at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6388, device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "evaluate_tm(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690\n",
      "Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099\n",
      "Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145\n",
      "Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963\n",
      "Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911\n",
      "Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965\n",
      "Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6061\n",
      "Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043\n",
      "Epoch 9/20, train loss: 0.3455, train metric: 0.5877, valid metric: 0.5723\n",
      "Epoch 10/20, train loss: 0.3416, train metric: 0.5846, valid metric: 0.6043\n",
      "Epoch 11/20, train loss: 0.3401, train metric: 0.5831, valid metric: 0.5882\n",
      "Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738\n",
      "Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5873\n",
      "Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5884\n",
      "Epoch 15/20, train loss: 0.3291, train metric: 0.5736, valid metric: 0.5608\n",
      "Epoch 16/20, train loss: 0.3272, train metric: 0.5721, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5839\n",
      "Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5661\n",
      "Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5556\n",
      "Epoch 20/20, train loss: 0.3190, train metric: 0.5649, valid metric: 0.5617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
    "               n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_tm(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 30), nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)\n",
    "\n",
    "# Since we compute the training metric\n",
    "plt.plot(np.arange(n_epochs) + 0.5, history[\"train_metrics\"], \".--\",\n",
    "         label=\"Training\")\n",
    "plt.plot(np.arange(n_epochs) + 1.0, history[\"valid_metrics\"], \".-\",\n",
    "         label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.axis([0.5, 20, 0.4, 1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Nonsequential Models Using Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + n_features, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        deep_output = self.deep_stack(X)\n",
    "        wide_and_deep = torch.concat([X, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = WideAndDeep(n_features).to(device)\n",
    "learning_rate = 0.002  # the model changed, so did the optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.7802, train metric: 1.3344, valid metric: 0.8690\n",
      "Epoch 2/20, train loss: 0.6201, train metric: 0.7875, valid metric: 0.9492\n",
      "Epoch 3/20, train loss: 0.5900, train metric: 0.7682, valid metric: 0.7331\n",
      "Epoch 4/20, train loss: 0.5607, train metric: 0.7488, valid metric: 0.7771\n",
      "Epoch 5/20, train loss: 0.5408, train metric: 0.7353, valid metric: 0.7967\n",
      "Epoch 6/20, train loss: 0.5244, train metric: 0.7241, valid metric: 0.7098\n",
      "Epoch 7/20, train loss: 0.5070, train metric: 0.7119, valid metric: 0.7419\n",
      "Epoch 8/20, train loss: 0.4941, train metric: 0.7030, valid metric: 0.6750\n",
      "Epoch 9/20, train loss: 0.4798, train metric: 0.6928, valid metric: 0.6762\n",
      "Epoch 10/20, train loss: 0.4657, train metric: 0.6825, valid metric: 0.6678\n",
      "Epoch 11/20, train loss: 0.4538, train metric: 0.6736, valid metric: 0.6617\n",
      "Epoch 12/20, train loss: 0.4441, train metric: 0.6665, valid metric: 0.6651\n",
      "Epoch 13/20, train loss: 0.4328, train metric: 0.6580, valid metric: 0.6803\n",
      "Epoch 14/20, train loss: 0.4232, train metric: 0.6506, valid metric: 0.6288\n",
      "Epoch 15/20, train loss: 0.4139, train metric: 0.6434, valid metric: 0.6202\n",
      "Epoch 16/20, train loss: 0.4063, train metric: 0.6374, valid metric: 0.6216\n",
      "Epoch 17/20, train loss: 0.3991, train metric: 0.6317, valid metric: 0.6129\n",
      "Epoch 18/20, train loss: 0.3937, train metric: 0.6274, valid metric: 0.6031\n",
      "Epoch 19/20, train loss: 0.3879, train metric: 0.6228, valid metric: 0.6092\n",
      "Epoch 20/20, train loss: 0.3834, train metric: 0.6193, valid metric: 0.5957\n"
     ]
    }
   ],
   "source": [
    "# extra code: train the model, exactly our previous models\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV2(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_wide = X[:, :5]\n",
    "        X_deep = X[:, 2:]\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = WideAndDeepV2(n_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.8482, train metric: 1.3598, valid metric: 0.9100\n",
      "Epoch 2/20, train loss: 0.6282, train metric: 0.7927, valid metric: 0.8028\n",
      "Epoch 3/20, train loss: 0.5763, train metric: 0.7591, valid metric: 0.7567\n",
      "Epoch 4/20, train loss: 0.5413, train metric: 0.7356, valid metric: 0.7290\n",
      "Epoch 5/20, train loss: 0.5099, train metric: 0.7142, valid metric: 0.7011\n",
      "Epoch 6/20, train loss: 0.4841, train metric: 0.6958, valid metric: 0.6816\n",
      "Epoch 7/20, train loss: 0.4656, train metric: 0.6824, valid metric: 0.6670\n",
      "Epoch 8/20, train loss: 0.4526, train metric: 0.6728, valid metric: 0.6576\n",
      "Epoch 9/20, train loss: 0.4438, train metric: 0.6662, valid metric: 0.6539\n",
      "Epoch 10/20, train loss: 0.4380, train metric: 0.6618, valid metric: 0.6498\n",
      "Epoch 11/20, train loss: 0.4326, train metric: 0.6577, valid metric: 0.6470\n",
      "Epoch 12/20, train loss: 0.4284, train metric: 0.6546, valid metric: 0.6447\n",
      "Epoch 13/20, train loss: 0.4253, train metric: 0.6521, valid metric: 0.6452\n",
      "Epoch 14/20, train loss: 0.4216, train metric: 0.6494, valid metric: 0.6468\n",
      "Epoch 15/20, train loss: 0.4190, train metric: 0.6473, valid metric: 0.6484\n",
      "Epoch 16/20, train loss: 0.4169, train metric: 0.6458, valid metric: 0.6452\n",
      "Epoch 17/20, train loss: 0.4144, train metric: 0.6438, valid metric: 0.6459\n",
      "Epoch 18/20, train loss: 0.4118, train metric: 0.6417, valid metric: 0.6470\n",
      "Epoch 19/20, train loss: 0.4101, train metric: 0.6404, valid metric: 0.6475\n",
      "Epoch 20/20, train loss: 0.4082, train metric: 0.6389, valid metric: 0.6493\n"
     ]
    }
   ],
   "source": [
    "# extra code: train the model, exactly our previous models\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV3(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        return self.output_layer(wide_and_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_data_wd = TensorDataset(X_train[:, :5], X_train[:, 2:], y_train)\n",
    "train_loader_wd = DataLoader(train_data_wd, batch_size=32, shuffle=True)\n",
    "valid_data_wd = TensorDataset(X_valid[:, :5], X_valid[:, 2:], y_valid)\n",
    "valid_loader_wd = DataLoader(valid_data_wd, batch_size=32)\n",
    "test_data_wd = TensorDataset(X_test[:, :5], X_test[:, 2:], y_test)\n",
    "test_loader_wd = DataLoader(test_data_wd, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
      "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
      "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
      "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
      "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
      "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
      "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
      "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
      "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
      "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
      "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
      "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
      "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
      "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
      "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
      "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
      "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
      "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
      "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
     ]
    }
   ],
   "source": [
    "def evaluate_multi_in(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for X_batch_wide, X_batch_deep, y_batch in data_loader:\n",
    "            X_batch_wide = X_batch_wide.to(device)\n",
    "            X_batch_deep = X_batch_deep.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_batch_wide, X_batch_deep)\n",
    "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
    "    return metric.compute()  # compute the final result at the end\n",
    "\n",
    "def train_multi_in(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for *X_batch_inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch_inputs = [X.to(device) for X in X_batch_inputs]\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(*X_batch_inputs)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_multi_in(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV3(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_multi_in(model, optimizer, mse, rmse, train_loader_wd,\n",
    "                         valid_loader_wd, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_wide, X_deep, y):\n",
    "        self.X_wide = X_wide\n",
    "        self.X_deep = X_deep\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_dict = {\"X_wide\": self.X_wide[idx], \"X_deep\": self.X_deep[idx]}\n",
    "        return input_dict, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_train[:, :5], X_deep=X_train[:, 2:], y=y_train)\n",
    "train_loader_named = DataLoader(train_data_named, batch_size=32, shuffle=True)\n",
    "valid_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_valid[:, :5], X_deep=X_valid[:, 2:], y=y_valid)\n",
    "valid_loader_named = DataLoader(valid_data_named, batch_size=32)\n",
    "test_data_named = WideAndDeepDataset(\n",
    "    X_wide=X_test[:, :5], X_deep=X_test[:, 2:], y=y_test)\n",
    "test_loader_named = DataLoader(test_data_named, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.8366, train metric: 0.9148, valid metric: 0.6892\n",
      "Epoch 2/20, train loss: 0.4627, train metric: 0.6803, valid metric: 0.6455\n",
      "Epoch 3/20, train loss: 0.4319, train metric: 0.6572, valid metric: 0.6374\n",
      "Epoch 4/20, train loss: 0.4259, train metric: 0.6525, valid metric: 0.6512\n",
      "Epoch 5/20, train loss: 0.4120, train metric: 0.6420, valid metric: 0.6305\n",
      "Epoch 6/20, train loss: 0.4040, train metric: 0.6356, valid metric: 0.6287\n",
      "Epoch 7/20, train loss: 0.4005, train metric: 0.6330, valid metric: 0.6252\n",
      "Epoch 8/20, train loss: 0.3976, train metric: 0.6306, valid metric: 0.6158\n",
      "Epoch 9/20, train loss: 0.3883, train metric: 0.6230, valid metric: 0.7407\n",
      "Epoch 10/20, train loss: 0.3866, train metric: 0.6218, valid metric: 0.6063\n",
      "Epoch 11/20, train loss: 0.3752, train metric: 0.6125, valid metric: 0.5974\n",
      "Epoch 12/20, train loss: 0.3704, train metric: 0.6087, valid metric: 0.5888\n",
      "Epoch 13/20, train loss: 0.3677, train metric: 0.6063, valid metric: 0.5981\n",
      "Epoch 14/20, train loss: 0.3604, train metric: 0.6004, valid metric: 0.5842\n",
      "Epoch 15/20, train loss: 0.3592, train metric: 0.5994, valid metric: 0.6410\n",
      "Epoch 16/20, train loss: 0.3640, train metric: 0.6034, valid metric: 0.5747\n",
      "Epoch 17/20, train loss: 0.3534, train metric: 0.5946, valid metric: 0.5686\n",
      "Epoch 18/20, train loss: 0.3461, train metric: 0.5883, valid metric: 0.5679\n",
      "Epoch 19/20, train loss: 0.3436, train metric: 0.5863, valid metric: 0.5621\n",
      "Epoch 20/20, train loss: 0.3414, train metric: 0.5843, valid metric: 0.5690\n"
     ]
    }
   ],
   "source": [
    "def evaluate_named(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(X_wide=inputs[\"X_wide\"], X_deep=inputs[\"X_deep\"])\n",
    "            metric.update(y_pred, y_batch)\n",
    "    return metric.compute()  # compute the final result at the end\n",
    "\n",
    "def train_named(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(**inputs)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_named(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV3(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_named(model, optimizer, mse, rmse, train_loader_named,\n",
    "                      valid_loader_named, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepV4(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.deep_stack = nn.Sequential(\n",
    "            nn.Linear(n_features - 2, 50), nn.ReLU(),\n",
    "            nn.Linear(50, 40), nn.ReLU(),\n",
    "            nn.Linear(40, 30), nn.ReLU(),\n",
    "        )\n",
    "        self.output_layer = nn.Linear(30 + 5, 1)\n",
    "        self.aux_output_layer = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, X_wide, X_deep):\n",
    "        deep_output = self.deep_stack(X_deep)\n",
    "        wide_and_deep = torch.concat([X_wide, deep_output], dim=1)\n",
    "        main_output = self.output_layer(wide_and_deep)\n",
    "        aux_output = self.aux_output_layer(deep_output)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 1.0693, train metric: 0.9506, valid metric: 0.7085\n",
      "Epoch 2/20, train loss: 0.5817, train metric: 0.6946, valid metric: 0.6607\n",
      "Epoch 3/20, train loss: 0.5010, train metric: 0.6581, valid metric: 0.6425\n",
      "Epoch 4/20, train loss: 0.4690, train metric: 0.6497, valid metric: 0.6654\n",
      "Epoch 5/20, train loss: 0.4503, train metric: 0.6420, valid metric: 0.6338\n",
      "Epoch 6/20, train loss: 0.4387, train metric: 0.6373, valid metric: 0.6563\n",
      "Epoch 7/20, train loss: 0.4315, train metric: 0.6330, valid metric: 0.6193\n",
      "Epoch 8/20, train loss: 0.4249, train metric: 0.6302, valid metric: 0.6167\n",
      "Epoch 9/20, train loss: 0.4116, train metric: 0.6202, valid metric: 0.6450\n",
      "Epoch 10/20, train loss: 0.4085, train metric: 0.6198, valid metric: 0.5938\n",
      "Epoch 11/20, train loss: 0.4073, train metric: 0.6197, valid metric: 0.5959\n",
      "Epoch 12/20, train loss: 0.3914, train metric: 0.6078, valid metric: 0.6073\n",
      "Epoch 13/20, train loss: 0.3847, train metric: 0.6033, valid metric: 0.5815\n",
      "Epoch 14/20, train loss: 0.3849, train metric: 0.6048, valid metric: 0.6042\n",
      "Epoch 15/20, train loss: 0.3744, train metric: 0.5965, valid metric: 0.5740\n",
      "Epoch 16/20, train loss: 0.3690, train metric: 0.5928, valid metric: 0.6111\n",
      "Epoch 17/20, train loss: 0.3675, train metric: 0.5923, valid metric: 0.5766\n",
      "Epoch 18/20, train loss: 0.3606, train metric: 0.5869, valid metric: 0.5782\n",
      "Epoch 19/20, train loss: 0.3604, train metric: 0.5867, valid metric: 0.5664\n",
      "Epoch 20/20, train loss: 0.3566, train metric: 0.5837, valid metric: 0.5654\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_multi_out(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for inputs, y_batch in data_loader:\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, _ = model(**inputs)\n",
    "            metric.update(y_pred, y_batch)\n",
    "    return metric.compute()\n",
    "\n",
    "def train_multi_out(model, optimizer, criterion, metric, train_loader,\n",
    "                   valid_loader, n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for inputs, y_batch in train_loader:\n",
    "            model.train()\n",
    "            inputs = {name: X.to(device) for name, X in inputs.items()}\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred, y_pred_aux = model(**inputs)\n",
    "            main_loss = criterion(y_pred, y_batch)\n",
    "            aux_loss = criterion(y_pred_aux, y_batch)\n",
    "            loss = 0.8 * main_loss + 0.2 * aux_loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_multi_out(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = WideAndDeepV4(n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train_multi_out(model, optimizer, mse, rmse, train_loader_named,\n",
    "                          valid_loader_named, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Image Classifier with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TorchVision to Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.3MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 178kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.26MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
    "\n",
    "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=True, download=True, transform=toTensor)\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=False, download=True, transform=toTensor)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_data, valid_data = torch.utils.data.random_split(\n",
    "    train_and_valid_data, [55_000, 5_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry is a tuple (image, target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image has a shape \\[channels, rows, columns\\]. Grayscale images like in Fashion MNIST have a single channel (while RGB images have 3, and other types of images, such as satellite images, may have many more). Fashion images are grayscale and 28x28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_valid_data.classes[y_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_inputs, n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mlp(X)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
    "                        n_classes=10).to(device)\n",
    "xentropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.6058, train metric: 0.7816, valid metric: 0.8416\n",
      "Epoch 2/20, train loss: 0.4059, train metric: 0.8497, valid metric: 0.8372\n",
      "Epoch 3/20, train loss: 0.3633, train metric: 0.8663, valid metric: 0.8530\n",
      "Epoch 4/20, train loss: 0.3359, train metric: 0.8762, valid metric: 0.8660\n",
      "Epoch 5/20, train loss: 0.3147, train metric: 0.8835, valid metric: 0.8754\n",
      "Epoch 6/20, train loss: 0.2991, train metric: 0.8881, valid metric: 0.8666\n",
      "Epoch 7/20, train loss: 0.2859, train metric: 0.8916, valid metric: 0.8622\n",
      "Epoch 8/20, train loss: 0.2745, train metric: 0.8971, valid metric: 0.8722\n",
      "Epoch 9/20, train loss: 0.2639, train metric: 0.9007, valid metric: 0.8834\n",
      "Epoch 10/20, train loss: 0.2531, train metric: 0.9041, valid metric: 0.8810\n",
      "Epoch 11/20, train loss: 0.2463, train metric: 0.9068, valid metric: 0.8850\n",
      "Epoch 12/20, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8910\n",
      "Epoch 13/20, train loss: 0.2303, train metric: 0.9125, valid metric: 0.8870\n",
      "Epoch 14/20, train loss: 0.2235, train metric: 0.9144, valid metric: 0.8734\n",
      "Epoch 15/20, train loss: 0.2154, train metric: 0.9184, valid metric: 0.8788\n",
      "Epoch 16/20, train loss: 0.2089, train metric: 0.9207, valid metric: 0.8826\n",
      "Epoch 17/20, train loss: 0.2030, train metric: 0.9234, valid metric: 0.8906\n",
      "Epoch 18/20, train loss: 0.1989, train metric: 0.9242, valid metric: 0.8884\n",
      "Epoch 19/20, train loss: 0.1924, train metric: 0.9271, valid metric: 0.8818\n",
      "Epoch 20/20, train loss: 0.1888, train metric: 0.9282, valid metric: 0.8716\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "_ = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader,\n",
    "           n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "X_new, y_new = next(iter(valid_loader))\n",
    "X_new = X_new[:3].to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred_logits = model(X_new)\n",
    "y_pred = y_pred_logits.argmax(dim=1)  # index of the largest logit\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sneaker', 'Coat', 'Pullover']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_and_valid_data.classes[index] for index in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the model made the correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All correct! 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.9110, 0.0000,\n",
       "         0.0880],\n",
       "        [0.0000, 0.0000, 0.0040, 0.0000, 0.9960, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.6250, 0.0000, 0.3350, 0.0000, 0.0390, 0.0000, 0.0000,\n",
       "         0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "y_proba = F.softmax(y_pred_logits, dim=1)\n",
    "if device == \"mps\":\n",
    "    y_proba = y_proba.cpu()\n",
    "y_proba.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9110, 0.0880, 0.0010, 0.0000],\n",
       "        [0.9960, 0.0040, 0.0000, 0.0000],\n",
       "        [0.6250, 0.3350, 0.0390, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_values, y_top4_indices = torch.topk(y_pred_logits, k=4, dim=1)\n",
    "y_top4_probas = F.softmax(y_top4_values, dim=1)\n",
    "if device == \"mps\":\n",
    "    y_top4_probas = y_top4_probas.cpu()\n",
    "y_top4_probas.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 9, 5, 8],\n",
       "        [4, 2, 6, 0],\n",
       "        [2, 4, 6, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_top4_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266610"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
    "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    accuracy = accuracy.to(device)\n",
    "    history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
    "                     valid_loader, n_epochs=10)\n",
    "    validation_accuracy = max(history[\"valid_metrics\"])\n",
    "    return validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:20:53,727] A new study created in memory with name: no-name-27fd1323-5c92-43f9-8071-fa800aebc54b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
      "Epoch 2/10, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
      "Epoch 3/10, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
      "Epoch 4/10, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
      "Epoch 5/10, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
      "Epoch 6/10, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
      "Epoch 7/10, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
      "Epoch 8/10, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
      "Epoch 9/10, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:23:25,327] Trial 0 finished with value: 0.6435999870300293 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.6435999870300293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
      "Epoch 1/10, train loss: 1.1459, train metric: 0.6229, valid metric: 0.7338\n",
      "Epoch 2/10, train loss: 0.6108, train metric: 0.7841, valid metric: 0.7992\n",
      "Epoch 3/10, train loss: 0.5203, train metric: 0.8169, valid metric: 0.8094\n",
      "Epoch 4/10, train loss: 0.4810, train metric: 0.8302, valid metric: 0.8310\n",
      "Epoch 5/10, train loss: 0.4557, train metric: 0.8404, valid metric: 0.8352\n",
      "Epoch 6/10, train loss: 0.4387, train metric: 0.8460, valid metric: 0.8442\n",
      "Epoch 7/10, train loss: 0.4240, train metric: 0.8512, valid metric: 0.8408\n",
      "Epoch 8/10, train loss: 0.4123, train metric: 0.8566, valid metric: 0.8514\n",
      "Epoch 9/10, train loss: 0.3998, train metric: 0.8601, valid metric: 0.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:25:57,218] Trial 1 finished with value: 0.8547999858856201 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 0.3897, train metric: 0.8638, valid metric: 0.8548\n",
      "Epoch 1/10, train loss: 2.3069, train metric: 0.1144, valid metric: 0.1082\n",
      "Epoch 2/10, train loss: 2.2993, train metric: 0.1231, valid metric: 0.1294\n",
      "Epoch 3/10, train loss: 2.2914, train metric: 0.1606, valid metric: 0.1710\n",
      "Epoch 4/10, train loss: 2.2836, train metric: 0.1839, valid metric: 0.1840\n",
      "Epoch 5/10, train loss: 2.2762, train metric: 0.1891, valid metric: 0.1856\n",
      "Epoch 6/10, train loss: 2.2692, train metric: 0.1910, valid metric: 0.1898\n",
      "Epoch 7/10, train loss: 2.2623, train metric: 0.1933, valid metric: 0.1932\n",
      "Epoch 8/10, train loss: 2.2554, train metric: 0.2000, valid metric: 0.2022\n",
      "Epoch 9/10, train loss: 2.2485, train metric: 0.2122, valid metric: 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:28:28,531] Trial 2 finished with value: 0.23340000212192535 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 2.2414, train metric: 0.2299, valid metric: 0.2334\n",
      "Epoch 1/10, train loss: 2.3035, train metric: 0.1373, valid metric: 0.1526\n",
      "Epoch 2/10, train loss: 2.3005, train metric: 0.1569, valid metric: 0.1724\n",
      "Epoch 3/10, train loss: 2.2975, train metric: 0.1755, valid metric: 0.1896\n",
      "Epoch 4/10, train loss: 2.2945, train metric: 0.1941, valid metric: 0.2132\n",
      "Epoch 5/10, train loss: 2.2914, train metric: 0.2105, valid metric: 0.2288\n",
      "Epoch 6/10, train loss: 2.2884, train metric: 0.2261, valid metric: 0.2418\n",
      "Epoch 7/10, train loss: 2.2853, train metric: 0.2419, valid metric: 0.2580\n",
      "Epoch 8/10, train loss: 2.2823, train metric: 0.2581, valid metric: 0.2742\n",
      "Epoch 9/10, train loss: 2.2792, train metric: 0.2736, valid metric: 0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:30:58,822] Trial 3 finished with value: 0.30959999561309814 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 2.2761, train metric: 0.2897, valid metric: 0.3096\n",
      "Epoch 1/10, train loss: 1.8379, train metric: 0.4869, valid metric: 0.6208\n",
      "Epoch 2/10, train loss: 0.9751, train metric: 0.6666, valid metric: 0.6978\n",
      "Epoch 3/10, train loss: 0.7608, train metric: 0.7253, valid metric: 0.7416\n",
      "Epoch 4/10, train loss: 0.6704, train metric: 0.7639, valid metric: 0.7720\n",
      "Epoch 5/10, train loss: 0.6108, train metric: 0.7913, valid metric: 0.7906\n",
      "Epoch 6/10, train loss: 0.5687, train metric: 0.8053, valid metric: 0.8050\n",
      "Epoch 7/10, train loss: 0.5386, train metric: 0.8164, valid metric: 0.8082\n",
      "Epoch 8/10, train loss: 0.5158, train metric: 0.8243, valid metric: 0.8214\n",
      "Epoch 9/10, train loss: 0.4988, train metric: 0.8279, valid metric: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:33:29,943] Trial 4 finished with value: 0.8220000267028809 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.8547999858856201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, train loss: 0.4842, train metric: 0.8330, valid metric: 0.8092\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.008471801418819975, 'n_hidden': 188}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547999858856201"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_loader, valid_loader):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\", 20, 300)\n",
    "    model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=n_hidden,\n",
    "                            n_hidden2=n_hidden, n_classes=10).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    accuracy = accuracy.to(device)\n",
    "    best_validation_accuracy = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        history = train2(model, optimizer, xentropy, accuracy, train_loader,\n",
    "                         valid_loader, n_epochs=1)\n",
    "        validation_accuracy = max(history[\"valid_metrics\"])\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "        trial.report(validation_accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return best_validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_with_data = lambda trial: objective(\n",
    "    trial, train_loader=train_loader, valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "objective_with_data = partial(objective, train_loader=train_loader,\n",
    "                              valid_loader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:33:29,993] A new study created in memory with name: no-name-38c4ab57-e010-4c31-b3e6-9cf84c20adce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 2.2769, train metric: 0.1471, valid metric: 0.1860\n",
      "Epoch 1/1, train loss: 2.2093, train metric: 0.2794, valid metric: 0.3500\n",
      "Epoch 1/1, train loss: 2.1164, train metric: 0.4110, valid metric: 0.4554\n",
      "Epoch 1/1, train loss: 1.9776, train metric: 0.5137, valid metric: 0.5562\n",
      "Epoch 1/1, train loss: 1.7867, train metric: 0.5826, valid metric: 0.6026\n",
      "Epoch 1/1, train loss: 1.5775, train metric: 0.6184, valid metric: 0.6228\n",
      "Epoch 1/1, train loss: 1.3978, train metric: 0.6288, valid metric: 0.6326\n",
      "Epoch 1/1, train loss: 1.2605, train metric: 0.6360, valid metric: 0.6372\n",
      "Epoch 1/1, train loss: 1.1572, train metric: 0.6468, valid metric: 0.6424\n",
      "Epoch 1/1, train loss: 1.0782, train metric: 0.6537, valid metric: 0.6436\n",
      "Epoch 1/1, train loss: 1.0162, train metric: 0.6611, valid metric: 0.6530\n",
      "Epoch 1/1, train loss: 0.9665, train metric: 0.6689, valid metric: 0.6620\n",
      "Epoch 1/1, train loss: 0.9258, train metric: 0.6761, valid metric: 0.6700\n",
      "Epoch 1/1, train loss: 0.8919, train metric: 0.6835, valid metric: 0.6782\n",
      "Epoch 1/1, train loss: 0.8629, train metric: 0.6897, valid metric: 0.6848\n",
      "Epoch 1/1, train loss: 0.8381, train metric: 0.6954, valid metric: 0.6876\n",
      "Epoch 1/1, train loss: 0.8166, train metric: 0.7009, valid metric: 0.6932\n",
      "Epoch 1/1, train loss: 0.7974, train metric: 0.7073, valid metric: 0.6964\n",
      "Epoch 1/1, train loss: 0.7802, train metric: 0.7119, valid metric: 0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 07:38:38,280] Trial 0 finished with value: 0.7089999914169312 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7089999914169312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.7647, train metric: 0.7196, valid metric: 0.7082\n",
      "Epoch 1/1, train loss: 1.1485, train metric: 0.6157, valid metric: 0.7332\n",
      "Epoch 1/1, train loss: 0.6133, train metric: 0.7864, valid metric: 0.8082\n",
      "Epoch 1/1, train loss: 0.5200, train metric: 0.8179, valid metric: 0.8136\n",
      "Epoch 1/1, train loss: 0.4783, train metric: 0.8311, valid metric: 0.8232\n",
      "Epoch 1/1, train loss: 0.4533, train metric: 0.8402, valid metric: 0.8020\n",
      "Epoch 1/1, train loss: 0.4357, train metric: 0.8465, valid metric: 0.8446\n",
      "Epoch 1/1, train loss: 0.4211, train metric: 0.8510, valid metric: 0.8276\n",
      "Epoch 1/1, train loss: 0.4083, train metric: 0.8562, valid metric: 0.8398\n",
      "Epoch 1/1, train loss: 0.3981, train metric: 0.8606, valid metric: 0.8532\n",
      "Epoch 1/1, train loss: 0.3881, train metric: 0.8640, valid metric: 0.8582\n",
      "Epoch 1/1, train loss: 0.3782, train metric: 0.8663, valid metric: 0.8532\n",
      "Epoch 1/1, train loss: 0.3699, train metric: 0.8693, valid metric: 0.8566\n",
      "Epoch 1/1, train loss: 0.3631, train metric: 0.8712, valid metric: 0.8574\n",
      "<<204 more lines>>\n",
      "Epoch 1/1, train loss: 0.2761, train metric: 0.8982, valid metric: 0.8792\n",
      "Epoch 1/1, train loss: 0.2684, train metric: 0.9003, valid metric: 0.8848\n",
      "Epoch 1/1, train loss: 0.2615, train metric: 0.9045, valid metric: 0.8772\n",
      "Epoch 1/1, train loss: 0.2560, train metric: 0.9049, valid metric: 0.8820\n",
      "Epoch 1/1, train loss: 0.2497, train metric: 0.9071, valid metric: 0.8832\n",
      "Epoch 1/1, train loss: 0.2434, train metric: 0.9097, valid metric: 0.8848\n",
      "Epoch 1/1, train loss: 0.2380, train metric: 0.9126, valid metric: 0.8832\n",
      "Epoch 1/1, train loss: 0.2331, train metric: 0.9145, valid metric: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:32:19,547] Trial 16 finished with value: 0.8848000168800354 and parameters: {'learning_rate': 0.032666299131732864, 'n_hidden': 142}. Best is trial 12 with value: 0.8867999911308289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.2271, train metric: 0.9154, valid metric: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:32:35,221] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 1.5604, train metric: 0.5038, valid metric: 0.6536\n",
      "Epoch 1/1, train loss: 0.6189, train metric: 0.7751, valid metric: 0.8314\n",
      "Epoch 1/1, train loss: 0.4237, train metric: 0.8447, valid metric: 0.8492\n",
      "Epoch 1/1, train loss: 0.3814, train metric: 0.8605, valid metric: 0.8582\n",
      "Epoch 1/1, train loss: 0.3567, train metric: 0.8681, valid metric: 0.8622\n",
      "Epoch 1/1, train loss: 0.3375, train metric: 0.8744, valid metric: 0.8674\n",
      "Epoch 1/1, train loss: 0.3246, train metric: 0.8788, valid metric: 0.8480\n",
      "Epoch 1/1, train loss: 0.3123, train metric: 0.8849, valid metric: 0.8644\n",
      "Epoch 1/1, train loss: 0.3012, train metric: 0.8871, valid metric: 0.8734\n",
      "Epoch 1/1, train loss: 0.2915, train metric: 0.8916, valid metric: 0.8760\n",
      "Epoch 1/1, train loss: 0.2858, train metric: 0.8931, valid metric: 0.8758\n",
      "Epoch 1/1, train loss: 0.2778, train metric: 0.8955, valid metric: 0.8804\n",
      "Epoch 1/1, train loss: 0.2715, train metric: 0.8972, valid metric: 0.8616\n",
      "Epoch 1/1, train loss: 0.2642, train metric: 0.9011, valid metric: 0.8800\n",
      "Epoch 1/1, train loss: 0.2598, train metric: 0.9009, valid metric: 0.8782\n",
      "Epoch 1/1, train loss: 0.2561, train metric: 0.9033, valid metric: 0.8734\n",
      "Epoch 1/1, train loss: 0.2494, train metric: 0.9058, valid metric: 0.8788\n",
      "Epoch 1/1, train loss: 0.2474, train metric: 0.9069, valid metric: 0.8720\n",
      "Epoch 1/1, train loss: 0.2411, train metric: 0.9089, valid metric: 0.8750\n",
      "Epoch 1/1, train loss: 0.2375, train metric: 0.9103, valid metric: 0.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:37:45,329] Trial 18 finished with value: 0.8830000162124634 and parameters: {'learning_rate': 0.0954812841907134, 'n_hidden': 50}. Best is trial 12 with value: 0.8867999911308289.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.2353, train metric: 0.9109, valid metric: 0.8830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 08:38:00,038] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, train loss: 0.7417, train metric: 0.7395, valid metric: 0.7640\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler,\n",
    "                            pruner=pruner)\n",
    "study.optimize(objective_with_data, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867999911308289"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08525846269447772, 'n_hidden': 116}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"my_fashion_mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"my_fashion_mnist.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "y_pred_logits = loaded_model(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"my_fashion_mnist_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = ImageClassifier(n_inputs=1 * 28 * 28, n_hidden1=300, n_hidden2=100,\n",
    "                            n_classes=10)\n",
    "loaded_weights = torch.load(\"my_fashion_mnist_weights.pt\", weights_only=True)\n",
    "new_model.load_state_dict(loaded_weights)\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"model_hyperparameters\": {\n",
    "        \"n_inputs\": 1 * 28 * 28,\n",
    "        \"n_hidden1\": 300,\n",
    "        \"n_hidden2\": 100,\n",
    "        \"n_classes\": 10,\n",
    "    }\n",
    "}\n",
    "torch.save(model_data, \"my_fashion_mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = torch.load(\"my_fashion_mnist_model.pt\", weights_only=True)\n",
    "new_model = ImageClassifier(**loaded_data[\"model_hyperparameters\"])\n",
    "new_model.load_state_dict(loaded_data[\"model_state_dict\"])\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Optimizing a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.trace(model, X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model = torch.jit.optimize_for_inference(torchscript_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model.save(\"my_fashion_mnist_torchscript.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_torchscript_model = torch.jit.load(\"my_fashion_mnist_torchscript.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.3324,  -0.7572,  -4.1671,  -1.9444,  -1.6955,   2.0123,  -3.2624,\n",
       "           8.6379,  -0.5685,   6.2972],\n",
       "        [ -0.1434,  -3.8626,  11.8279,  -0.3164,  17.3995, -13.1888,   7.8158,\n",
       "         -11.8338,  -1.4709,  -7.9412],\n",
       "        [  0.3996,  -2.5537,   7.5992,   0.1775,   6.9748,  -6.1942,   4.8270,\n",
       "          -5.8584,  -1.4327,  -4.3257]], device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logits = loaded_torchscript_model(X_new)\n",
    "y_pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 08:38:10.662000 360 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    }
   ],
   "source": [
    "if device == \"cuda\":\n",
    "    y_pred_logits = compiled_model(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work in progress\n",
    "\n",
    "I'm working on the exercise solutions, hoping to finish them by December 2025. Thanks for your patience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
